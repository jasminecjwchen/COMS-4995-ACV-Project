{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "871c32c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from PIL import Image\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, recall_score, accuracy_score\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from sklearn.metrics import recall_score\n",
    "from tqdm import tqdm\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eed212ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratedImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.label_names = {'Live': 0, 'Print': 1, 'Papercut': 2, 'Replay': 3, '3D': 4}\n",
    "        \n",
    "        for label_name, label in self.label_names.items():\n",
    "            label_dir = os.path.join(self.root_dir, label_name)\n",
    "            for img_name in os.listdir(label_dir):\n",
    "                self.images.append(os.path.join(label_dir, img_name))\n",
    "                self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4028eb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 16 * 16, 128)  \n",
    "        self.fc2 = nn.Linear(128, 5)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(x.size(0), -1)  \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0bba0fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # Resize the images\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize the images\n",
    "])\n",
    "\n",
    "pretrain_dataset = GeneratedImageDataset(root_dir='generated_data/', transform=transform)\n",
    "pretrain_loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a2b1b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 10] loss: 1.5177\n",
      "[1, 60] loss: 1.9713\n",
      "[1, 110] loss: 0.6261\n",
      "[2, 10] loss: 0.1046\n",
      "[2, 60] loss: 0.3117\n",
      "[2, 110] loss: 0.2325\n",
      "[3, 10] loss: 0.0239\n",
      "[3, 60] loss: 0.1303\n",
      "[3, 110] loss: 0.2046\n",
      "[4, 10] loss: 0.0276\n",
      "[4, 60] loss: 0.0358\n",
      "[4, 110] loss: 0.1060\n",
      "[5, 10] loss: 0.0074\n",
      "[5, 60] loss: 0.0338\n",
      "[5, 110] loss: 0.0351\n",
      "[6, 10] loss: 0.0023\n",
      "[6, 60] loss: 0.0152\n",
      "[6, 110] loss: 0.0221\n",
      "[7, 10] loss: 0.0090\n",
      "[7, 60] loss: 0.1026\n",
      "[7, 110] loss: 0.0220\n",
      "[8, 10] loss: 0.0058\n",
      "[8, 60] loss: 0.0148\n",
      "[8, 110] loss: 0.0797\n",
      "[9, 10] loss: 0.0596\n",
      "[9, 60] loss: 0.0503\n",
      "[9, 110] loss: 0.0158\n",
      "[10, 10] loss: 0.0026\n",
      "[10, 60] loss: 0.0291\n",
      "[10, 110] loss: 0.0064\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(pretrain_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 50 == 9:\n",
    "            print(f'[{epoch + 1}, {i + 1}] loss: {running_loss / 10:.4f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad770ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = GeneratedImageDataset(root_dir='multiclass_data/', transform=transform)\n",
    "\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "dataloaders = {'train': train_loader, 'val': val_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dcd7327a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "----------\n",
      "TRAIN Loss: 0.4000 Acc: 0.8590 Precision: 0.8456 Recall: 0.8306 F1: 0.8371\n",
      "VAL Loss: 0.1937 Acc: 0.9365 Precision: 0.9321 Recall: 0.9250 F1: 0.9280\n",
      "Epoch 2/5\n",
      "----------\n",
      "TRAIN Loss: 0.1394 Acc: 0.9539 Precision: 0.9498 Recall: 0.9491 F1: 0.9494\n",
      "VAL Loss: 0.1479 Acc: 0.9503 Precision: 0.9536 Recall: 0.9412 F1: 0.9465\n",
      "Epoch 3/5\n",
      "----------\n",
      "TRAIN Loss: 0.0750 Acc: 0.9760 Precision: 0.9750 Recall: 0.9754 F1: 0.9752\n",
      "VAL Loss: 0.1426 Acc: 0.9600 Precision: 0.9598 Recall: 0.9548 F1: 0.9572\n",
      "Epoch 4/5\n",
      "----------\n",
      "TRAIN Loss: 0.0474 Acc: 0.9841 Precision: 0.9829 Recall: 0.9830 F1: 0.9830\n",
      "VAL Loss: 0.1617 Acc: 0.9554 Precision: 0.9591 Recall: 0.9515 F1: 0.9550\n",
      "Epoch 5/5\n",
      "----------\n",
      "TRAIN Loss: 0.0327 Acc: 0.9890 Precision: 0.9889 Recall: 0.9890 F1: 0.9890\n",
      "VAL Loss: 0.1804 Acc: 0.9591 Precision: 0.9591 Recall: 0.9560 F1: 0.9572\n",
      "Training and evaluation complete\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    print('-' * 10)\n",
    "    \n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train() \n",
    "        else:\n",
    "            model.eval()   \n",
    "\n",
    "        running_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        for inputs, labels in dataloaders[phase]:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "        epoch_accuracy = accuracy_score(all_labels, all_preds)\n",
    "        epoch_precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "        epoch_recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "        epoch_f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "\n",
    "        print(f'{phase.upper()} Loss: {epoch_loss:.4f} Acc: {epoch_accuracy:.4f} Precision: {epoch_precision:.4f} Recall: {epoch_recall:.4f} F1: {epoch_f1:.4f}')\n",
    "\n",
    "print('Training and evaluation complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35fa38c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'gan_simple_cnn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389f44cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
